{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "import re\n",
    "import os\n",
    "import string\n",
    "import nltk\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import explained_variance_score\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, mean_squared_error\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "from sklearn.svm import SVC\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding\n",
    "from keras.layers.core import Dense, SpatialDropout1D\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "description    15234\n",
       "category       15234\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "path = \"\\\\\".join(os.getcwd().split(\"\\\\\")[:-1])\n",
    "dataset = pd.read_csv(path + \"\\\\finalData.csv\")\n",
    "dataset = dataset[dataset['civic_issue']==1]\n",
    "dataset = dataset[['description','category']]\n",
    "dataset.drop_duplicates(subset='description',inplace=True,keep=False)\n",
    "dataset.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Preprocessing the Description \n",
    " \n",
    " The preprocessing is done in 4 steps:\n",
    "\n",
    "    - removing punctuation\n",
    "    - removing stopwords like 'the', 'this','as',etc\n",
    "    - conversion of the entire text to lower case\n",
    "    - Stemming: reducing the number of inflectional forms of words by reducing all to their common stem.For example, 'argue','arguing','argued' are all reduced to 'argu'\n",
    "    - Splitting dataset into train and cross validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess():\n",
    "    stemmer = PorterStemmer()\n",
    "    words = stopwords.words(\"english\")\n",
    "    dataset['processedtext'] = dataset['description'].apply(lambda x: \" \".join([stemmer.stem(i) for i in re.sub(\"[^a-zA-Z]\", \" \", x).split() if i not in words]).lower())\n",
    "\n",
    "preprocess()\n",
    "data = dataset[['processedtext','category']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data['processedtext'],data['category'], test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining functions to calculate model metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def auc_roc(classifier):\n",
    "    pred_probs = classifier.predict_proba(test_tfidf)\n",
    "    train_probs = classifier.predict_proba(train_tfidf)[:,1]\n",
    "    noSkillProb = [0 for _ in range(len(y_test))]\n",
    "    lr_probs = pred_probs[:,1]\n",
    "\n",
    "    noSkillAUC = roc_auc_score(y_test,noSkillProb)\n",
    "    logRegAUC = roc_auc_score(y_test,lr_probs)\n",
    "\n",
    "    print('No Skill: ROC AUC=%.3f' % (noSkillAUC))\n",
    "    print('Logistic: ROC AUC=%.3f' % (logRegAUC))\n",
    "\n",
    "    #FPR,TPR,thresholds = roc_curve(y_test,)\n",
    "    ns_fpr, ns_tpr, _ = roc_curve(y_test, noSkillProb)\n",
    "    lr_fpr, lr_tpr, _ = roc_curve(y_test, lr_probs)\n",
    "    t_fpr,t_tpr,_ = roc_curve(y_train,train_probs)\n",
    "    # plot the roc curve for the model\n",
    "    plt.plot(ns_fpr, ns_tpr, linestyle='--', label='No Skill')\n",
    "    plt.plot(lr_fpr, lr_tpr, marker='.', label='Logistic')\n",
    "    plt.plot(t_fpr,t_tpr,marker='*',label='Training')\n",
    "    # axis labels\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    # show the legend\n",
    "    plt.legend()\n",
    "    # show the plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def model_metrics(classifier,y_test,pred,score):\n",
    "    print(\"Accuracy:\", score*100, \"%\")\n",
    "    # print(\"Precision:\",precision_score(y_test,pred)*100,\"%\")\n",
    "    # print(\"Recall:\",recall_score(y_test,pred)*100,\"%\")\n",
    "    # print(\"F1 Score:\",f1_score(y_test,pred)*100,\"%\")\n",
    "    # print(\"MSE:\",mean_squared_error(y_test,pred)*100,\"%\")\n",
    "    # print(\"Explained Variance Regression Score:\", explained_variance_score(y_test,pred))\n",
    "    # auc_roc(classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Linear SVC Model and Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "\n",
      "Train Accuracy: 92.64790350373349 %\n",
      "\n",
      "\n",
      "Accuracy: 85.16573679028554 %\n"
     ]
    }
   ],
   "source": [
    "def train_SVC(train_tfIdf, y_train):\n",
    "    #building text classification model using Linear Kernel SVC Classifier (has highest accuracy)\n",
    "    classifier = SVC(kernel='linear') #accuracy obtained for linear kernel = 83.28%\n",
    "    classifier.fit(train_tfIdf, y_train) #fitting the classifier onto the training data\n",
    "    filename = \"linearkernelSVC.sav\"\n",
    "    pickle.dump(classifier,open(filename,\"wb\"))\n",
    "\n",
    "def predict_cat():  \n",
    "    # X_train: description data for training\n",
    "    # y_train: corresponding categories for training\n",
    "    # X_test and y_test: description and category for testing\n",
    "    \n",
    "    # Vectorizing the train and test data using TfIDf vectorization\n",
    "    # TfIdf - Text Frequency Inverse Document Freqeuncy : vectorizes based on frequency across the current text document but less frequency across multiple documents\n",
    "\n",
    "    vectorizer_tfidf = TfidfVectorizer(stop_words='english', max_df=0.7) #initializing the vector\n",
    "    train_tfIdf = vectorizer_tfidf.fit_transform(X_train.values.astype('U')) #astype('U') converts the dataframe into a Unicode array\n",
    "    test_tfIdf = vectorizer_tfidf.transform(X_test.values.astype('U'))#transforming the text into frequency vectors\n",
    "    \n",
    "    # train_SVC(train_tfIdf, y_train)\n",
    "\n",
    "    classifier = pickle.load(open(\"linearkernelSVC.sav\",\"rb\"))\n",
    "    predictions = classifier.predict(test_tfIdf) #predictions made on the unseen data\n",
    "    train_score = classifier.score(train_tfIdf, y_train)\n",
    "    print(\"\\n\\nTrain Accuracy:\",train_score*100,\"%\\n\\n\")\n",
    "    score = classifier.score(test_tfIdf,y_test)\n",
    "    model_metrics(classifier,y_test,predictions,score)\n",
    "\n",
    "predict_cat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Waste/Garbage' 'Air' 'Streetlights' 'Traffic/Parking' 'Sewage'\n",
      " 'Potholes' 'Electricity' 'Water' 'Plastic' 'Sanitation']\n"
     ]
    }
   ],
   "source": [
    "print(dataset['category'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20201 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "# The maximum number of words to be used. (most frequent)\n",
    "MAX_NB_WORDS = 50000\n",
    "# Max number of words in each complaint.\n",
    "MAX_SEQUENCE_LENGTH = 500\n",
    "# This is fixed.\n",
    "EMBEDDING_DIM = 100\n",
    "tokenizer = Tokenizer(num_words=MAX_NB_WORDS, filters='!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~', lower=True)\n",
    "tokenizer.fit_on_texts(dataset['description'].values)\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data tensor: (15234, 500)\n"
     ]
    }
   ],
   "source": [
    "X = tokenizer.texts_to_sequences(dataset['description'].values)\n",
    "X = pad_sequences(X, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "print('Shape of data tensor:', X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of label tensor: (15234, 10)\n"
     ]
    }
   ],
   "source": [
    "Y = pd.get_dummies(dataset['category']).values\n",
    "print('Shape of label tensor:', Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12187, 500) (12187, 10)\n",
      "(3047, 500) (3047, 10)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size = 0.20, random_state = 42)\n",
    "print(X_train.shape,Y_train.shape)\n",
    "print(X_test.shape,Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "172/172 [==============================] - 234s 1s/step - loss: 1.3335 - accuracy: 0.6096 - val_loss: 0.9802 - val_accuracy: 0.6891\n",
      "Epoch 2/5\n",
      "172/172 [==============================] - 167s 971ms/step - loss: 0.7730 - accuracy: 0.7567 - val_loss: 0.7404 - val_accuracy: 0.7834\n",
      "Epoch 3/5\n",
      "172/172 [==============================] - 164s 956ms/step - loss: 0.4985 - accuracy: 0.8476 - val_loss: 0.6695 - val_accuracy: 0.7900\n",
      "Epoch 4/5\n",
      "172/172 [==============================] - 168s 975ms/step - loss: 0.3694 - accuracy: 0.8901 - val_loss: 0.6348 - val_accuracy: 0.8236\n",
      "Epoch 5/5\n",
      "172/172 [==============================] - 168s 975ms/step - loss: 0.2710 - accuracy: 0.9233 - val_loss: 0.6729 - val_accuracy: 0.8236\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(MAX_NB_WORDS, EMBEDDING_DIM, input_length=X.shape[1]))\n",
    "model.add(SpatialDropout1D(0.2))\n",
    "model.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "epochs = 5\n",
    "batch_size = 64\n",
    "\n",
    "history = model.fit(X_train, Y_train, epochs=epochs, batch_size=batch_size,validation_split=0.1,callbacks=[EarlyStopping(monitor='val_loss', patience=3, min_delta=0.0001)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96/96 [==============================] - 11s 111ms/step - loss: 0.6886 - accuracy: 0.8192\n",
      "Test set\n",
      "  Loss: 0.689\n",
      "  Accuracy: 0.819\n"
     ]
    }
   ],
   "source": [
    "accr = model.evaluate(X_test,Y_test)\n",
    "print('Test set\\n  Loss: {:0.3f}\\n  Accuracy: {:0.3f}'.format(accr[0],accr[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.06495962 0.01019261 0.00348917 0.01619492 0.01081865 0.00263569\n",
      "  0.04165866 0.81442034 0.03258398 0.0030464 ]] Traffic/Parking\n"
     ]
    }
   ],
   "source": [
    "new_complaint = ['The Bangalore traffic is adding to the pollution in the city.'] #bruh it isnt really accurate\n",
    "seq = tokenizer.texts_to_sequences(new_complaint)\n",
    "padded = pad_sequences(seq, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "pred = model.predict(padded)\n",
    "labels = dataset['category']\n",
    "print(pred, labels[np.argmax(pred)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}