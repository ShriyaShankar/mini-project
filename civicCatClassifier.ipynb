{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.6 64-bit (conda)",
   "metadata": {
    "interpreter": {
     "hash": "a0d4e06333e6cb61b4bbbc9d8fc792d4f6006fe6306b4a2b7b8e18ab0a2621e6"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "import re\n",
    "import os\n",
    "import string\n",
    "import nltk\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import explained_variance_score\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, mean_squared_error\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "from sklearn.svm import SVC\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "description    15234\n",
       "category       15234\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "dataset = pd.read_csv(\"finalData.csv\")\n",
    "dataset = dataset[dataset['civic_issue']==1]\n",
    "dataset = dataset[['description','category']]\n",
    "dataset.drop_duplicates(subset='description',inplace=True,keep=False)\n",
    "dataset.count()"
   ]
  },
  {
   "source": [
    " ## Preprocessing the Description \n",
    " \n",
    " The preprocessing is done in 4 steps:\n",
    "\n",
    "    - removing punctuation\n",
    "    - removing stopwords like 'the', 'this','as',etc\n",
    "    - conversion of the entire text to lower case\n",
    "    - Stemming: reducing the number of inflectional forms of words by reducing all to their common stem.For example, 'argue','arguing','argued' are all reduced to 'argu'\n",
    "    - Splitting dataset into train and cross validation sets"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess():\n",
    "    stemmer = PorterStemmer()\n",
    "    words = stopwords.words(\"english\")\n",
    "    dataset['processedtext'] = dataset['description'].apply(lambda x: \" \".join([stemmer.stem(i) for i in re.sub(\"[^a-zA-Z]\", \" \", x).split() if i not in words]).lower())\n",
    "\n",
    "preprocess()\n",
    "data = dataset[['processedtext','category']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data['processedtext'],data['category'], test_size=0.20, random_state=42)"
   ]
  },
  {
   "source": [
    "### Defining functions to calculate model metrics"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def auc_roc(classifier):\n",
    "    pred_probs = classifier.predict_proba(test_tfidf)\n",
    "    train_probs = classifier.predict_proba(train_tfidf)[:,1]\n",
    "    noSkillProb = [0 for _ in range(len(y_test))]\n",
    "    lr_probs = pred_probs[:,1]\n",
    "\n",
    "    noSkillAUC = roc_auc_score(y_test,noSkillProb)\n",
    "    logRegAUC = roc_auc_score(y_test,lr_probs)\n",
    "\n",
    "    print('No Skill: ROC AUC=%.3f' % (noSkillAUC))\n",
    "    print('Logistic: ROC AUC=%.3f' % (logRegAUC))\n",
    "\n",
    "    #FPR,TPR,thresholds = roc_curve(y_test,)\n",
    "    ns_fpr, ns_tpr, _ = roc_curve(y_test, noSkillProb)\n",
    "    lr_fpr, lr_tpr, _ = roc_curve(y_test, lr_probs)\n",
    "    t_fpr,t_tpr,_ = roc_curve(y_train,train_probs)\n",
    "    # plot the roc curve for the model\n",
    "    plt.plot(ns_fpr, ns_tpr, linestyle='--', label='No Skill')\n",
    "    plt.plot(lr_fpr, lr_tpr, marker='.', label='Logistic')\n",
    "    plt.plot(t_fpr,t_tpr,marker='*',label='Training')\n",
    "    # axis labels\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    # show the legend\n",
    "    plt.legend()\n",
    "    # show the plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def model_metrics(classifier,y_test,pred,score):\n",
    "    print(\"Accuracy:\", score*100, \"%\")\n",
    "    # print(\"Precision:\",precision_score(y_test,pred)*100,\"%\")\n",
    "    # print(\"Recall:\",recall_score(y_test,pred)*100,\"%\")\n",
    "    # print(\"F1 Score:\",f1_score(y_test,pred)*100,\"%\")\n",
    "    # print(\"MSE:\",mean_squared_error(y_test,pred)*100,\"%\")\n",
    "    # print(\"Explained Variance Regression Score:\", explained_variance_score(y_test,pred))\n",
    "    # auc_roc(classifier)"
   ]
  },
  {
   "source": [
    "## Training the Linear SVC Model and Cross Validation"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "\n",
      "Train Accuracy: 92.64790350373349 %\n",
      "\n",
      "\n",
      "Accuracy: 85.16573679028554 %\n"
     ]
    }
   ],
   "source": [
    "def train_SVC(train_tfIdf, y_train):\n",
    "    #building text classification model using Linear Kernel SVC Classifier (has highest accuracy)\n",
    "    classifier = SVC(kernel='linear') #accuracy obtained for linear kernel = 83.28%\n",
    "    classifier.fit(train_tfIdf, y_train) #fitting the classifier onto the training data\n",
    "    filename = \"linearkernelSVC.sav\"\n",
    "    pickle.dump(classifier,open(filename,\"wb\"))\n",
    "\n",
    "def predict_cat():  \n",
    "    # X_train: description data for training\n",
    "    # y_train: corresponding categories for training\n",
    "    # X_test and y_test: description and category for testing\n",
    "    \n",
    "    # Vectorizing the train and test data using TfIDf vectorization\n",
    "    # TfIdf - Text Frequency Inverse Document Freqeuncy : vectorizes based on frequency across the current text document but less frequency across multiple documents\n",
    "\n",
    "    vectorizer_tfidf = TfidfVectorizer(stop_words='english', max_df=0.7) #initializing the vector\n",
    "    train_tfIdf = vectorizer_tfidf.fit_transform(X_train.values.astype('U')) #astype('U') converts the dataframe into a Unicode array\n",
    "    test_tfIdf = vectorizer_tfidf.transform(X_test.values.astype('U'))#transforming the text into frequency vectors\n",
    "    \n",
    "    # train_SVC(train_tfIdf, y_train)\n",
    "\n",
    "    classifier = pickle.load(open(\"linearkernelSVC.sav\",\"rb\"))\n",
    "    predictions = classifier.predict(test_tfIdf) #predictions made on the unseen data\n",
    "    train_score = classifier.score(train_tfIdf, y_train)\n",
    "    print(\"\\n\\nTrain Accuracy:\",train_score*100,\"%\\n\\n\")\n",
    "    score = classifier.score(test_tfIdf,y_test)\n",
    "    model_metrics(classifier,y_test,predictions,score)\n",
    "\n",
    "predict_cat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}